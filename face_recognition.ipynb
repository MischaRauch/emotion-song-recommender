{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 16:02:57.106220: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/opt/anaconda3/envs/IS/lib/python3.10/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.1.0)/charset_normalizer (None) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "from deepface import DeepFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 4/4 [00:00<00:00,  7.08it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'emotion': {'angry': 5.058629955030782e-16, 'disgust': 1.3592825033951627e-28, 'fear': 2.2512698819590643e-17, 'happy': 99.99958872792654, 'sad': 3.6078986726967884e-15, 'surprise': 1.6338946771474983e-13, 'neutral': 0.0004126845642947006}, 'dominant_emotion': 'happy', 'region': {'x': 1953, 'y': 746, 'w': 1170, 'h': 1170}, 'age': 24, 'gender': {'Woman': 0.13234749203547835, 'Man': 99.86764788627625}, 'dominant_gender': 'Man', 'race': {'asian': 0.04358116420917213, 'indian': 0.16676425002515316, 'black': 0.006122087506810203, 'white': 84.05798673629761, 'middle eastern': 7.28401318192482, 'latino hispanic': 8.441534638404846}, 'dominant_race': 'white'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "face_analysis = DeepFace.analyze(img_path = \"/Users/mischatomaszrauch/UM/AcademicYear_03/04_Period/IntelligentSystems/emotion-song-recommender/database/Mischa.jpg\")\n",
    "print(face_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "facial recognition model VGG-Face is just built\n",
      "Age model is just built\n",
      "Gender model is just built\n",
      "Emotion model is just built\n",
      "WARNING: Representations for images in database folder were previously stored in representations_vgg_face.pkl. If you added new instances after the creation, then please delete this file and call find function again. It will create it again.\n",
      "There are  1  representations found in  representations_vgg_face.pkl\n",
      "find function lasts  0.5489389896392822  seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@15.541] global /private/var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_5a1v4y7k9y/croot/opencv-suite_1676472757237/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    }
   ],
   "source": [
    "data = DeepFace.stream('database')\n",
    "print(data)\n",
    "#Read more at: https://viso.ai/computer-vision/deepface/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import get_songs as gs\n",
    "import models.load_model as model_library\n",
    "\n",
    "# Ele's client ID\n",
    "CLIENT_ID = '6e1a09c940a943da95144c6f49a0717b'\n",
    "CLIENT_PASSWORD = 'ccc2af43075641f9899eaaac5b716b8b'\n",
    "sp = gs.authenticate(CLIENT_ID, CLIENT_PASSWORD)\n",
    "mischasPreference = ['rock','pop','ambiente']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SONG  10    230480\n",
      "Name: length, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "songs = gs.get_songs(sp, 100, gs.get_playlist_URI(sp, mischasPreference[0]))\n",
    "#songs.append(gs.get_songs(sp, 100, gs.get_playlist_URI(sp, mischasPreference[1])))\n",
    "#songs.append(gs.get_songs(sp, 100, gs.get_playlist_URI(sp, mischasPreference[2])))\n",
    "data = gs.create_table_songs(sp, songs)\n",
    "\n",
    "current_song = data.sample(1) # Assuming is a df with one sample\n",
    "print(\"SONG \",current_song['length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230480"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_song['length'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-17 16:44:59.997278: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[ WARN:0@46.521] global /private/var/folders/sy/f16zz6x50xz3113nwtb9bvq00000gp/T/abs_5a1v4y7k9y/croot/opencv-suite_1676472757237/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m cam\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m      9\u001b[0m cv2\u001b[39m.\u001b[39mimwrite(\u001b[39m'\u001b[39m\u001b[39mtest.png\u001b[39m\u001b[39m'\u001b[39m,image)\n\u001b[0;32m---> 10\u001b[0m data \u001b[39m=\u001b[39m DeepFace\u001b[39m.\u001b[39;49manalyze(image)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/IS/lib/python3.10/site-packages/deepface/DeepFace.py:313\u001b[0m, in \u001b[0;36manalyze\u001b[0;34m(img_path, actions, enforce_detection, detector_backend, align, silent)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39m# ---------------------------------\u001b[39;00m\n\u001b[1;32m    311\u001b[0m resp_objects \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 313\u001b[0m img_objs \u001b[39m=\u001b[39m functions\u001b[39m.\u001b[39;49mextract_faces(\n\u001b[1;32m    314\u001b[0m     img\u001b[39m=\u001b[39;49mimg_path,\n\u001b[1;32m    315\u001b[0m     target_size\u001b[39m=\u001b[39;49m(\u001b[39m224\u001b[39;49m, \u001b[39m224\u001b[39;49m),\n\u001b[1;32m    316\u001b[0m     detector_backend\u001b[39m=\u001b[39;49mdetector_backend,\n\u001b[1;32m    317\u001b[0m     grayscale\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    318\u001b[0m     enforce_detection\u001b[39m=\u001b[39;49menforce_detection,\n\u001b[1;32m    319\u001b[0m     align\u001b[39m=\u001b[39;49malign,\n\u001b[1;32m    320\u001b[0m )\n\u001b[1;32m    322\u001b[0m \u001b[39mfor\u001b[39;00m img_content, img_region, _ \u001b[39min\u001b[39;00m img_objs:\n\u001b[1;32m    323\u001b[0m     \u001b[39mif\u001b[39;00m img_content\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m img_content\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/IS/lib/python3.10/site-packages/deepface/commons/functions.py:115\u001b[0m, in \u001b[0;36mextract_faces\u001b[0;34m(img, target_size, detector_backend, grayscale, enforce_detection, align)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39m# in case of no face found\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(face_objs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m enforce_detection \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 115\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    116\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFace could not be detected. Please confirm that the picture is a face photo \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    117\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mor consider to set enforce_detection param to False.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    118\u001b[0m     )\n\u001b[1;32m    120\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(face_objs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m enforce_detection \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     face_objs \u001b[39m=\u001b[39m [(img, img_region, \u001b[39m0\u001b[39m)]\n",
      "\u001b[0;31mValueError\u001b[0m: Face could not be detected. Please confirm that the picture is a face photo or consider to set enforce_detection param to False."
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import time\n",
    "from deepface import DeepFace\n",
    "cam = cv2.VideoCapture(0)\n",
    "# wait to get enough light for image\n",
    "time.sleep(3)\n",
    "_, image = cam.read()\n",
    "cam.release()\n",
    "cv2.imwrite('test.png',image)\n",
    "data = DeepFace.analyze(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2aeff055a6fd6269121c8648d9820a62d2720ac3b7fb7cb1b9fc158514b37176"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
